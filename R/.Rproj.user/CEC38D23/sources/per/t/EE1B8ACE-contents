---
title: "Feature Importance Exploration - No IgM"
output:
  html_document: default
  pdf_document: default
  word_document: default
---


# Import libraries

```{r include=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(here)
library(glmnet)
library(xgboost)
```

# Load Data

This block performs the following operations:

1. Loads the raw data.
2. Selects the desired predictor variables.
3. Drops rows with missing data.
4. Prepares the target variable, transforming it from 4 classes to 2.

```{r}
set.seed(88)
data_csv <- here("data", "raw", "final_data.csv")
df <- read.csv(data_csv, stringsAsFactors = FALSE)
# Import Erasmus
erasmus_csv <- here("data", "interim", "190611_longitudinal.csv")
eras_df <- read.csv(erasmus_csv, stringsAsFactors = FALSE)

eras_df <- eras_df %>% 
  filter(Sample != "np-001v4") %>% 
  mutate(Subset = "Test")

eras_samp <- eras_df$Sample

df <- df %>%
  filter(!Sample %in% eras_samp) %>% 
  mutate(Subset = "Train")
```

```{r}
not_all_na <- function(x) {!all(is.na(x))}
eras_df <- eras_df %>%
  select_if(not_all_na)

df <- df %>% 
  select(names(eras_df))

df <- rbind(df, eras_df)

df <- df %>% 
  select(-Sample) %>% 
  drop_na() %>% 
  mutate(Cohort = factor(if_else(Cohort %in% c("PP", "NP", "PP_Erasmus"), "Primary", "Latent")))

```

# Split

```{r}
erasmus <- df %>% 
  filter(Subset == "Test") %>% 
  select(-Subset)

df <- df %>% 
  filter(Subset == "Train") %>% 
  drop_na() %>% 
  select(-Subset)

```
# Preprocessing

The following block uses the `recipes` library to log scale and normalize the predictors between 0 and 1.

```{r}
rec_obj <- recipe(Cohort ~ ., data = df)

normalizer <- rec_obj %>% 
  step_log(all_predictors()) %>% 
  step_range(all_predictors(), min = 0, max = 1)

trained_rec <- prep(normalizer, training = df)

norm_df <- bake(trained_rec, df)
norm_eras <- bake(trained_rec, erasmus)
```


# Predicting

The following block performs 10-fold cross validation using lasso regression with the `glmnet` package. `mod_df` removes all `IgM` features.

```{r}
# mod_df <- norm_df
mod_df <- norm_df[, -grep("^IgM", colnames(norm_df))]
mod_eras <- norm_eras[, -grep("^IgM", colnames(norm_eras))]

perm_df <- norm_df[, -grep("^IgM", colnames(norm_df))] %>% 
  mutate(permCohort = sample(norm_df$Cohort), nrow(norm_df)) %>% 
  select(-Cohort)
```

```{r}
myGrid = expand.grid(
  alpha = 1,
  lambda = seq(0.0001, 1, length = 100)
)

model <- train(
  Cohort ~ ., 
  mod_df, 
  method = 'glmnet',
  tuneGrid = myGrid,
  na.action = na.pass,
  trControl = trainControl(
    method = "cv",
    number = 10,
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    verboseIter = TRUE
  )
)
model
```

The following block repeats the operation in the previous block with permuted labels in order to simulate the null hypothesis.

```{r}
permModel <- train(
  permCohort ~ ., 
  perm_df, 
  method = 'glmnet',
  tuneGrid = myGrid,
  trControl = trainControl(
    method = "cv",
    number = 10,
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    verboseIter = TRUE
  )
)
permModel
```

The following block plots the ROC-AUC metric distributions for the real and permuted versions of the `glmnet` model as violin plots.

```{r}

realSamps <- model$resample %>% 
  mutate(model = "Real")

permSamps <- permModel$resample %>% 
  mutate(model = "Permuted")

box_df <- bind_rows(realSamps, permSamps)

ggplot(box_df, aes(fct_relevel(model, c("Real", "Permuted")), ROC)) +
  geom_violin() +
  expand_limits(y = 0) +
  labs(title = "ROC Distribution by CV Fold",
       x = "Model Run",
       y = "ROC AUC")
```

The following block plots the coefficients from the best model identified by `glmnet`.

```{r}
# Predictor
feature_matrix <- mod_df %>% 
  select(-Cohort) %>% 
  as.matrix()

# Target
cohort <- mod_df$Cohort

form = c("Cohort ~ FcAR_postfusion.gB + IgA_CG2 + IgA1_CG1 + IgA1_CG2 + IgA2_CG1 + IgA2_postfusion.gB + IgG3_CG2 + IgG3_pentamer + aHu2AR_CG1")

lasso_fit <- glm(formula(form), data = mod_df , family = binomial)

lasso_fit %>% 
  tidy() %>% 
  arrange(desc(estimate)) %>% 
  filter(term != "(Intercept)") %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot(aes(term, estimate)) +
  geom_col() +
  coord_flip() +
  labs(title = "Coefficients in predictive model",
       subtitle = "Based on LASSO regression",
       x = "",
       y = "Coefficient")
```

# Evaluating

This block evaluates the performance of the model using the ROC metric.

```{r}
library(caTools)
preds <- predict(lasso_fit, mod_df, type = "response")

colAUC(preds, cohort, plotROC = TRUE)
```

```{r}
for_plot <- tibble(cohort, preds)
names(for_plot) <- c("Cohort", "Preds")

ggplot(for_plot) +
  aes(Cohort, Preds) +
  geom_jitter()
```

```{r}
# Predictor
feature_matrix_eras <- norm_eras %>% 
  select(names(mod_df)) %>% 
  select(-Cohort)

# Target
cohort <- norm_eras$Cohort

eras_preds <- predict(lasso_fit, feature_matrix_eras, type = "response")

```

```{r}
for_plot <- tibble(cohort, eras_preds)
names(for_plot) <- c("Cohort", "Preds")

ggplot(for_plot) +
  aes(Cohort, Preds) +
  geom_jitter()
```

```{r}
hi <- tibble(cohort, eras_samp, eras_preds)
hi
```
```{r}
visit_four <- hi %>% 
  filter(str_detect(eras_samp, pattern = "v")) %>% 
  mutate(Week = "Four")

visit_three <- hi %>% 
  filter(!str_detect(eras_samp, pattern = "v")) %>% 
  mutate(Week = "One")

visit_four$eras_samp <- visit_four$eras_samp %>% 
  str_replace("v4", "") %>% 
  str_replace("v", "")

names(visit_three) <- c("Cohort", "Sample", "Prob", "Visit")
names(visit_four) <- c("Cohort", "Sample", "Prob", "Visit")

visit_three <- visit_three %>% 
  filter(Sample %in% visit_four$Sample)

visit_four <- visit_four %>% 
  filter(Sample %in% visit_three$Sample)

beforeafter <- rbind(visit_three, visit_four)

orders = c("One", "Four")

beforeafter <- beforeafter %>% 
  mutate(Visit = factor(Visit, levels = orders))
```

```{r}
ggplot(beforeafter) +
  aes(x = Visit, y = Prob, col = Cohort, group = Sample) +
  geom_point() +
  geom_line(show.legend = F) +
  labs(
    title = "Prediction Change in Longitudinal Samples",
    y = "Predicted Probability - Primary"
  )

ggsave("190612_longitudinal_change.png")
```

This block trains an XGBoost model in order to investigate feature importance.

```{r}
labels = ifelse(mod_df$Cohort == "Primary", 1, 0)

dtrain <- mod_df %>%
  select(-Cohort) %>% 
  as.matrix() %>% 
  xgb.DMatrix(label = labels)

xgb_params <- list(
  booster = "gbtree",
  objective = "binary:logistic"
)

model_xgb <- xgb.train(
  params = xgb_params,
  data = dtrain,
  print_every_n = 5,
  nrounds = 60,
  verbose = 1
)
```

This block displays the feature importance metric from XGBoost. This displays the number of times the tree-based model split on a particular feature in order to perform classification. The more times a particular feature is chosen for a split, the more crucial it is to the model.

```{r}
importance_matrix <- xgb.importance(model = model_xgb)
xgb.ggplot.importance(importance_matrix)
```

The following three plots scatter features chosen by the models as important against each other. As you can see, there is a lot of separation in many cases.

```{r}
ggplot(norm_df, aes(x = IgM.1000f_gB, y = IgM.1000f_postfusion.gB, color = Cohort)) +
  geom_point() +
  labs(title = "IgM.1000f_postfusion.gB vs. IgM.1000f_gB")
```

```{r}
ggplot(norm_df, aes(x = IgA2_CG2, y = IgA1_CG1, color = Cohort)) +
  geom_point() +
  labs(title = "IgA1_CG1 vs. IgA2_CG2")
```

```{r}
ggplot(norm_df, aes(x = IgG3_pentamer, y = IgA1_CG1, color = Cohort)) +
  geom_point() +
  labs(title = "IgA1_CG1 vs. IgG3_pentamer")
```