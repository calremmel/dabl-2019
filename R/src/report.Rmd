---
title: "Feature Importance Exploration - No IgM"
output:
  html_document: default
  pdf_document: default
  word_document: default
---


# Import libraries

```{r include=FALSE}
library(tidyverse)
library(caret)
library(recipes)
library(here)
library(glmnet)
library(xgboost)
```

# Load Data

This block performs the following operations:

1. Loads the raw data.
2. Selects the desired predictor variables.
3. Drops rows with missing data.
4. Prepares the target variable, transforming it from 4 classes to 2.

```{r}
set.seed(88)
data_csv <- here("data", "raw", "final_data.csv")
df <- read.csv(data_csv)

df <- df %>% 
  select(-Sample) %>% 
  drop_na() %>% 
  mutate(Cohort = factor(if_else(Cohort %in% c("PP", "NP"), "Primary", "Latent")))
```

# Preprocessing

The following block uses the `recipes` library to log scale and normalize the predictors between 0 and 1.

```{r}
rec_obj <- recipe(Cohort ~ ., data = df)

normalizer <- rec_obj %>% 
  step_log(all_predictors()) %>% 
  step_range(all_predictors(), min = 0, max = 1)

trained_rec <- prep(normalizer, training = df)

norm_df <- bake(trained_rec, df)
```

# Predicting

The following block performs 10-fold cross validation using lasso regression with the `glmnet` package. `mod_df` removes all `IgM` features.

```{r}
# mod_df <- norm_df
mod_df <- norm_df[, -grep("^IgM", colnames(norm_df))]

perm_df <- mod_df %>% 
  mutate(permCohort = sample(mod_df$Cohort), nrow(mod_df)) %>% 
  select(-Cohort)
```

```{r}
myGrid = expand.grid(
  alpha = 1,
  lambda = seq(0.0001, 1, length = 100)
)

model <- train(
  Cohort ~ ., 
  mod_df, 
  method = 'glmnet',
  tuneGrid = myGrid,
  trControl = trainControl(
    method = "cv",
    number = 10,
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    verboseIter = TRUE
  )
)
model
```

The following block repeats the operation in the previous block with permuted labels in order to simulate the null hypothesis.

```{r}
permModel <- train(
  permCohort ~ ., 
  perm_df, 
  method = 'glmnet',
  tuneGrid = myGrid,
  trControl = trainControl(
    method = "cv",
    number = 10,
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    verboseIter = TRUE
  )
)
permModel
```

The following block plots the ROC-AUC metric distributions for the real and permuted versions of the `glmnet` model as violin plots.

```{r}

realSamps <- model$resample %>% 
  mutate(model = "Real")

permSamps <- permModel$resample %>% 
  mutate(model = "Permuted")

box_df <- bind_rows(realSamps, permSamps)

ggplot(box_df, aes(fct_relevel(model, c("Real", "Permuted")), ROC)) +
  geom_violin() +
  expand_limits(y = 0) +
  labs(title = "ROC Distribution by CV Fold",
       x = "Model Run",
       y = "ROC AUC")
```

The following block plots the coefficients from the best model identified by `glmnet`.

```{r}
# Predictor
feature_matrix <- mod_df %>% 
  select(-Cohort) %>% 
  as.matrix()

# Target
cohort <- mod_df$Cohort

lasso_fit <- glmnet(feature_matrix, cohort, family = "binomial", alpha = 1, lambda = model$bestTune$lambda)

lasso_fit %>% 
  tidy() %>% 
  arrange(desc(estimate)) %>% 
  filter(term != "(Intercept)") %>% 
  mutate(term = fct_reorder(term, estimate)) %>% 
  ggplot(aes(term, estimate)) +
  geom_col() +
  coord_flip() +
  labs(title = "Coefficients in predictive model",
       subtitle = "Based on LASSO regression",
       x = "",
       y = "Coefficient")
```

# Evaluating

This block evaluates the performance of the model using the ROC metric.

```{r}
library(caTools)
preds <- predict(lasso_fit, feature_matrix, type = "response")

colAUC(preds, cohort, plotROC = TRUE)
```

This block trains an XGBoost model in order to investigate feature importance.

```{r}
labels = ifelse(mod_df$Cohort == "Primary", 1, 0)

dtrain <- mod_df %>%
  select(-Cohort) %>% 
  as.matrix() %>% 
  xgb.DMatrix(label = labels)

xgb_params <- list(
  booster = "gbtree",
  objective = "binary:logistic"
)

model_xgb <- xgb.train(
  params = xgb_params,
  data = dtrain,
  print_every_n = 5,
  nrounds = 60,
  verbose = 1
)
```

This block displays the feature importance metric from XGBoost. This displays the number of times the tree-based model split on a particular feature in order to perform classification. The more times a particular feature is chosen for a split, the more crucial it is to the model.

```{r}
importance_matrix <- xgb.importance(model = model_xgb)
xgb.ggplot.importance(importance_matrix)
```

The following three plots scatter features chosen by the models as important against each other. As you can see, there is a lot of separation in many cases.

```{r}
ggplot(norm_df, aes(x = IgM.1000f_gB, y = IgM.1000f_postfusion.gB, color = Cohort)) +
  geom_point() +
  labs(title = "IgM.1000f_postfusion.gB vs. IgM.1000f_gB")
```

```{r}
ggplot(norm_df, aes(x = IgA2_CG2, y = IgA1_CG1, color = Cohort)) +
  geom_point() +
  labs(title = "IgA1_CG1 vs. IgA2_CG2")
```

```{r}
ggplot(norm_df, aes(x = IgG3_pentamer, y = IgA1_CG1, color = Cohort)) +
  geom_point() +
  labs(title = "IgA1_CG1 vs. IgG3_pentamer")
```